---
title: |
  | Introduction to the Design and Analysis of Randomized Experiments
  | Class 5: Encouragment Designs, Instrumental Variables, Randomized Assignment but Not-Randomized Compliance
date: '`r format(Sys.Date(), "%B %d, %Y")`'
author: Jake Bowers
bibliography:
 - ../course.bib
fontsize: 10pt
graphics: yes
biblio-style: authoryear-comp
link-citations: true
biblatexoptions:
  - natbib=true
header-includes: |
  \setbeameroption{hide notes}
  \usepackage{hyperref}
  \usepackage{bookmark}
  \setbeamertemplate{footline}{\begin{beamercolorbox}{section in head/foot}
  \insertframenumber/\inserttotalframenumber \end{beamercolorbox}}
  \setbeamertemplate{itemize item}[circle]
  \setbeamertemplate{itemize subitem}{\raisebox{0.2em}{\scalebox{1}{$\blacktriangleright$}}}
  \setbeamersize{description width=2ex}
  \setbeamersize{text margin left=1ex,text margin right=1ex}
  \usepackage{tikz}
  \usepackage{tikz-cd}
  \usepackage{textpos}
  \usepackage{booktabs,multirow,makecell}
  \usepgflibrary{arrows}
  \usetikzlibrary{arrows}
  \tikzstyle{every picture}+=[remember picture]
  \newcommand{\theHtable}{\thetable}
  \usepackage{amsmath,amsthm}
output:
  beamer_presentation:
    slide_level: 2
    keep_tex: true
    toc: true
    latex_engine: lualatex
    citation_package: biblatex
    incremental: false
    md_extensions: +raw_attribute-tex_math_single_backslash+autolink_bare_uris+ascii_identifiers+tex_math_dollars
    pandoc_args: [ "--csl", "chicago-author-date.csl", "--toc" ]
colorlinks: true
---

```{r setup, include=FALSE,echo=FALSE}
# Load all the libraries we need
library(here)
library(kableExtra)
library(styler)
library(coin)
library(multcomp)
library(devtools)
library(randomizr)
library(rcompanion) ## for pairwisePermutationTest()
library(DeclareDesign)
library(estimatr)
library(tidyverse)
library(RItools)
```

```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

## from https://bookdown.org/yihui/rmarkdown-cookbook/font-color.html
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf(
      "<span style='color: %s;'>%s</span>", color,
      x
    )
  } else {
    x
  }
}
```


```{r makedat, echo=FALSE}
## First, create some data,
##  y0 is potential outcome to control
N <- 20
set.seed(123)
dat <- data.frame(
  y0 = c(rpois(N - 2, lambda = 2), rpois(2, lambda = 100))
)
## Just messing around with heterogeneous treatment effects
dat$tau0 <- rnorm(n = N, mean = 0, sd = sd(dat$y0))
dat$tau <- ifelse(dat$tau0 < 0, 0, signif(dat$tau0, 2))
dat$T <- complete_ra(N)
dat$y1 <- with(dat, y0 + tau)
dat$Y <- with(dat, T * y1 + (1 - T) * y0)
dat$Ybin <- as.numeric(dat$Y > median(dat$Y))
## Setup for use with coin
dat$TF <- factor(dat$T)
```



# Overview and Review

##  Today

  0. Quiz and Questions
  1. Missing data in experiments
  2. Designs and assumptions to learn about the LATE/CACE:
    - When you can randomize something but not everything, what can you learn?
      (Answer, quite a lot under some assumptions either using randomization as
      an instrumental variable or using a placebo design.)
  3. Open Discussions: Topics new and old. Things we didn't get around to
     discussing. Things that were confusing.

Note: You can download (and contribute to) course materials at [https://github.com/bowers-illinois-edu/short_course_experiments](https://github.com/bowers-illinois-edu/short_course_experiments)

Hay recursos en espaÃ±ol aqui: <https://egap.github.io/theory_and_practice_of_field_experiments_spanish/>

## Lingering Questions?

Questions arising?

## Quiz and Questions

- What are the three main ingredients of statistical power of a hypothesis
  test?
- In terms of those ingredients:
  - Why would a rank-based test statistic or a top-coded (or otherwise trimmed
    mean) based test statistic have more power than a simple difference of
    means?
  - Why would "covariance adjustment" improve power?
  - Why would block-randomization improve power?
  - Why might using an index of multiple measures of an outcome improve power?
- How might we make some informed guesses about the power of statistical tests
  given a research design?
- Why would a researcher publish an analysis plan before fielding an
  experiment? Why would academic journals start to require a "pre-analysis
  plan"?


## Key points for this lecture

 - Attrition (missing data on outcomes) can lead to bias and confounding and
   problems specifying the correct randomization distribution.

 - Non-compliance can teach us about the effect of the "active ingredient" of
   the treatment.
    - We can learn about the causal effect of the active ingredient using
      randomization as an instrument
    - Or we can learn about the same causal effect using a placebo design
      [@nickerson2005scalable],[@broockman2016durably].

# Missing data in experiments

## Attrition (missing data on outcomes)

- Some units may have missing data on outcomes (= units attrit) when:

  - some respondents can't be found or refuse to participate in endline data collection.

  - some records are lost.

- This is a problem when treatment affects missingness.

  - For example, units in control may be less willing to answer survey questions.
  - For example, treatment may have caused units to migrate and cannot be reached

- If we analyze the data by dropping units with missing outcomes, then we are
  no longer comparing similar treatment and control groups.
   - If observed and/or unobserved covariates drive the process of missing
     outcomes, then treated and control groups no longer have the same
     probability of treatment.

## What can we do?

- Check whether attrition rates are similar in treatment and control groups.

- Check whether treatment and control groups have similar covariate profiles.

- Do not drop observations that are missing outcome data from your analysis.

- When outcome data are missing we can sometimes **bound** our estimates of treatment effects.
   - Set the missing outcome data to the maximum value and then estimate a treatment effect
   - Set the missing outcome data to the minimum value and then estimate a treatment effect


## What can we do?

- But the best approach is to try to anticipate and prevent attrition.

   - Blind people to their treatment status.

   - Promise to deliver the treatment to the control group after the research is completed.

   - Plan ex ante to reach all subjects at endline.

   - Budget for intensive follow-up with a random sample of attriters.

## Missing data on covariates is not as problematic

- Missing **background covariates** (i.e.,variables for which values do not change as a result of treatment) for some observations is less problematic.

  - We can still learn about the causal effect of an experiment without those covariates, as we saw in the [Hypothesis Testing](hypothesistesting.html) and the [Estimation](estimation.html) modules.

  - We can also use the background covariate as planned by imputing for the missing values.

  - We can also condition on that missingness directly.

## Missing data on treatment assignment or blocks or clusters is a big problem

This would cause very similar problem as would missing data on outcomes.

## Summary: Missing data in experiments

 - Missing data on covariates is not a problem: it should be balanced by randomization.
 - Missing data on outcomes is a problem: it can remove the benefits of the randomization.
 - Missing data on treatment assignment is a problem: it can remove the benefits of the randomization.

Given missing data on outcomes:

 - Check to see if treatment predicts missingness
 - Check to see if missingness patterns relate strongly to covariates.
 - Report results using bounds (set all outcomes to max and min, report both results)
 - Report results using sensitivity analysis (like an observational study (see @rosenbaum2017observation)).

# Non-compliance:  Using Placebo Designs to estimate Causal effects when we do not control the dose

## Non-compliance or Encouragement Designs {.allowframebreaks}

  - Sometimes units assigned to treatment don't take it.  They don't comply with their assignment.

      - If all units assigned to control do not take the treatment, but only some units assigned to treatment take the treatment, we have _one-sided non-compliance_ [@gerber_field_2012,Chapter 5].

  - The effect of **treatment assignment** (often called the Intent to Treat Effect or ITT)  is not the same as the effect of **receiving a dose of the treatment**.

      - Not random who takes a dose of the treatment. Directly comparing people who take a dose with those who did not ("per protocol" or "as treated" comparisons) is not justified by randomization.

## Non-compliance or Encouragement Designs {.allowframebreaks}

  - The effect of receiving the treatment is often called the "Local Average Treatment Effect" (LATE) or "Complier Average Causal Effect" (CACE) (same quantity).

      - "Local" refers to the idea that the effect only occurs on the people
        who take the treatment when assigned to treatment (the kinds of people
        who 'comply' with the intentions of the researcher).

  - Two main approaches to estimation:
     1. Instrumental variable (in which random assignment may be a good instrument and often we estimate the CACE using 2SLS) (See @gerber_field_2012 Chapter 5) and
     2. Placebo-controlled experiments (@nickerson2005scalable, example @broockman2016durably). In which we estimate the CACE by comparing outcomes of treated and placebo groups.


## How to learn about the CACE/LATE using a Placebo

Imagine a door-to-door communication experiment where some houses are randomly
assigned to receive a visit and some attitude is measured as an outcome later.
Note that we now use $Z$ (treatment assigned) and $D$ (treatment taken) instead
of just $T$.


\begin{center}
\begin{tikzcd}[ampersand replacement=\&]
Z  \arrow[from=1-1,to=1-2, "\ne 0"]  \& D  \arrow[from=1-2,to=1-4] \& \& Y \\
(x_1 \ldots x_p) \arrow[from=2-1,to=1-1, "\text{0 (randomized)}"]  \arrow[from=2-1,to=1-2] \arrow[from=2-1,to=1-4]
\end{tikzcd}
\end{center}


 - $Z_i$ is random assignment to a visit ($Z_i=1$) or not ($Z_i=0$).
 - $D_i(Z_i=1)=1$ means that person $i$ would open the door to have a conversation when assigned a visit (it is a potential dose)
 - $D_i(Z_i=1)=0$ means that person $i$ would not open the door to have a conversation when assigned a visit.
 - $x_1 \ldots x_p$ are background covariates --- confounders of the $D_i \rightarrow Y_i$ relationship.


## How to learn about the CACE/LATE using a Placebo


\begin{center}
\begin{tikzcd}[ampersand replacement=\&]
Z  \arrow[from=1-1,to=1-2, "\ne 0"]  \& D  \arrow[from=1-2,to=1-4] \& \& Y \\
(x_1 \ldots x_p) \arrow[from=2-1,to=1-1, "\text{0 (randomized)}"]  \arrow[from=2-1,to=1-2] \arrow[from=2-1,to=1-4]
\end{tikzcd}
\end{center}


 - $Z_i$ is random assignment to a visit ($Z_i=1$) or not ($Z_i=0$).
 - $D_i(Z_i=1)=1$ means that person $i$ would open the door to have a conversation when assigned a visit (it is a potential dose)
 - $D_i(Z_i=1)=0$ means that person $i$ would not open the door to have a conversation when assigned a visit.
 - $x_1 \ldots x_p$ are background covariates --- confounders of the $D_i \rightarrow Y_i$ relationship.
 - So, $D_i$ is **an intermediate outcome:** $D_i = Z_i * D_i(1) + (1-Z_i) D_i(0)$.
 - $Y_i(Z_i=1,D_i(Z_i=1)=1)$ is primary outcome when $i$ is assigned to treatment **and** would open the door.


## Defining causal effects

So now we have four potential outcomes per person.

 - $Y_{i}(Z_i = 1, D_i=1)$ is the potential outcome for people who were assigned a visit and who opened the door. ("Compliers" or "Always-takers")

 - $Y_{i}(1, D_i=0)$ is the potential outcome for people who were assigned a visit and who did not open the door. ("Never-takers" or "Defiers")

 - $Y_{i}(0, D_i=1)$ is the potential outcome for people who were not assigned a visit and who opened the door. ("Defiers" or "Always-takers")

 - $Y_{i}(0, D_i=0)$ is the potential outcome for people who were not assigned a visit and who did not open the door. ("Compliers" or "Never-takers")

## Defining causal effects

The average causal effect of the "intention to visit people" is the ITT
(averaging over whether or not people opened the door):

\begin{equation}
ITT=ITT_Y=\delta= \bar{Y}(Z=1) - \bar{Y}(Z=0).
\end{equation}

The average causal effect of talking with someone at the door is the average treatment effect on compliers (the type of person who would open the door if visited) or the CACE:

\begin{equation}
CACE=\bar{Y}(Z_i=1,D_i=1|D_i(1)=1) - \bar{Y}(Z_i=0,D_i=0|D_i(1)=1)
\end{equation}

This is the same as the Local Average Treatment Effect (LATE).

## How to estimate the CACE using a Placebo Design?

We can estimate the average outcome among those assigned to treatment who
opened their doors ($\bar{Y}(Z_i=1,D_i=1|D_i(1)=1)$) because there are no
"always-takers" (i.e. people can only talk with a canvasser if a canvesser
shows up).

\begin{equation}
\hat{\bar{Y}}_i(Z_i=1,D_i=1|D_i(1)=1)=\sum_i \frac{(Z_i D_i Y_i)}{\sum_i D_i}
\end{equation}

Key here:  **we use the design and context knowledge to claim that only
compliers open the door when visited.**

## How to estimate the CACE using a Placebo Design?

What about  $\bar{Y}(Z_i=0,D_i=0|D_i(1)=1)$? How to learn about the outcome of
people not assigned treatment but who would have opened their door if visited?
(Hmm...We don't know whether they would have opened the door because they were
not assigned a visit!)

What about a placebo? The Nickerson placebo-controlled design  adds an arm to
the experiment. For example,  $Z_i=2$, where:

- **the compliance should be the same as treatment ($D_i(Z_i=2)=D_i(Z_i=1)$)** and
- **outcome should be the same as control ($Y_i(Z_i=2)=Y_i(Z_i=0)$)**.

And where the $Z_i=2$ is independent of all $x_1 \ldots x_p$ because of
randomization. So people in $Z_i=2$ are not systematically different from
people in $Z_i=1$ or $Z_i=0$.

## How to estimate the CACE using a Placebo Design?

This means that for:
\begin{equation}
CACE=\bar{Y}(Z_i=1,D_i=1|D_i(1)=1) - \bar{Y}(Z_i=0,D_i=0|D_i(1)=1)
\end{equation}

We can estimate it with
\begin{equation}
\widehat{CACE}= \left( \sum_i \frac{(I(Z_i=1) D_i Y_i)}{\sum_i I(Z_i=1) D_i} \right) - \left( \sum_i \frac{(I(Z_i=2) D_i Y_i)}{\sum_i I(Z_i=2) D_i} \right)
\end{equation}

Notice: we can check the assumptions:

  - same compliance pattern (and same complier types between treatment and placebo): $D_i(Z_i=2)=D_i(Z_i=1)$
  - same outcome pattern between placebo and control: $Y_i(Z_i=2)=Y_i(Z_i=0)$

## Example from Broockman and Kalla using Nickerson

For example see that paper.

## Summary

 - Analyze as you randomized, even when you don't control the dose, to get the
   ITT (very common in policy contexts).
 - The danger of per-protocol analysis (comparing based on $D_i$ is an
   observational study, not a randomized experiment)
 - If a placebo-controlled study doesn't work for you, you can use an
   instrumental variable approach (see @gerber_field_2012 chapter 5)

# Learning about the CACE/LATE using randomization as an instrument

## Defining causal effects

We have four potential outcomes per person.

 - $Y_{i}(Z_i = 1, D_i=1)$ is the potential outcome for people who were assigned a visit and who opened the door. ("Compliers" or "Always-takers")

 - $Y_{i}(1, D_i=0)$ is the potential outcome for people who were assigned a visit and who did not open the door. ("Never-takers" or "Defiers")

 - $Y_{i}(0, D_i=1)$ is the potential outcome for people who were not assigned a visit and who opened the door. ("Defiers" or "Always-takers")

 - $Y_{i}(0, D_i=0)$ is the potential outcome for people who were not assigned a visit and who did not open the door. ("Compliers" or "Never-takers")


## Defining causal effects II

 We could also write $Y_{i}(Z_i = 0, D_i(Z_i=1)=1)$ for people who were not
 assigned a visit but who would have opened the door had they been assigned a
 visit etc.

In this case we can simplify our potential outcomes:

$Y_{i}(0, D_{i}(1)=1) = Y_{i}(0,D_{i}(1)=0) = Y_{i}(0,D_{i}(0)=0)$ because your
outcome is the same regardless of how you don't open the door because you were
not assigned a visit.


## Defining causal effects III

We can simplify the ways in which people get a dose of the treatment like so

 - $Y$ : outcome ($Y_{i}(Z_i=1)$ for potential outcome to
   treatment for person $i$, fixed)
 - $X$ : covariate/baseline variable
 - $Z$ : treatment assignment ($Z_i=1$ if assigned to a visit, $Z_i=0$ if not
   assigned to a visit)
 - $D$ : treatment received ($D_i=1$ if answered phone, $D_i=0$ if person $i$
   did not answer the door) (using $D$ here because $D_i = D_{i}(1) Z_{i} + D_{i}(0) (1-Z_i)$)

## Defining causal effects IV

We have two causal effects of $Z$: $Z \rightarrow Y$ (this effect is often known as $\delta$, ITT, ITT$_Y$),
and $Z \rightarrow D$ (Gerber and Green call this ITT$_D$).

And different types of people can react differently to the attempt to move the
dose with the instrument.

\centering
\begin{tabular}{llcc}
                       &        & \multicolumn{2}{c}{$Z=1$} \\
		       &       & $D=0$ & $D=1$ \\
		       \midrule
\multirow{2}{*}{$Z=0$} & $D=0$ & Never taker & Complier \\
                       & $D=1$ & Defier     & Always taker \\
		       \bottomrule
\end{tabular}


##  Defining causal effects VI

The $ITT=ITT_Y=\delta= \bar{Y}(Z=1) - \bar{Y}(Z=0)$.

\medskip

But, in this design, we can split $\bar{Y}(Z=1)=\bar{Y}(1)$ into pieces: the outcome of
those who answered the door (Compliers and Always-takers and Defiers). Write
$p_C$ for the proportion of compliers in the study.

\begin{equation}
\bar{Y}(1)=(\bar{Y}(1)|C)p_C + (\bar{Y}(1)|A)p_A + (\bar{Y}(1)|N)p_N + (\bar{Y}(1)|D)p_D.
\end{equation}

And $\bar{Y}(0)$ is also split into pieces:

\begin{equation}
\bar{Y}(0)=(\bar{Y}(0)|C)p_C + (\bar{Y}(1)|A)p_A + (\bar{Y}(0)|N)p_N + (\bar{y}_0|D)p_D.
\end{equation}

##  Defining causal effects VII

So, the ITT itself is a combination of the effects of $Z$ on $Y$ within these
different groups (imagine substituting in and then re-arranging so that we
have a set of ITTs, one for each type of subject). But, we can still estimate it because we have unbiased
estimators of $\bar{Y}(1)$ and $\bar{y}_0$ within each type.

## Learning about the ITT I

First, let's learn about the effect of the policy itself. To write down the
ITT, we do not need to consider all of the types above.  We have no defiers
($p_D=0$) and we know the ITT for both Always-takers and Never-takers is 0.

\begin{equation}
\bar{Y}(1)=(\bar{Y}(1)|C)p_C + (\bar{Y}(1)|A)p_A + (\bar{Y}(1)|N)p_N
\end{equation}

\begin{equation}
\bar{Y}(0)=(\bar{Y}(0)|C)p_C + (\bar{Y}(0)|A)p_A + (\bar{Y}(0)|N)p_N
\end{equation}


## Learning about the ITT II

First, let's learn about the effect of the policy itself. To write down the
ITT, we do not need to consider all of the types above.  We have no defiers
($p_D=0$) and we know the ITT for both Always-takers and Never-takers is 0.


\begin{align}
ITT    = & \bar{Y}(1) - \bar{Y}(0) \\
        = & ( (\bar{Y}(1)|C)p_C + (\bar{Y}(1)|A)p_A + (\bar{Y}(1)|N)p_N ) - \\
       & ( (\bar{Y}(0)|C)p_C + (\bar{Y}(0)|A)p_A + (\bar{Y}(0)|N)p_N )  \\
       \intertext{collecting each type together --- to have an ITT for each type}
       = & ( (\bar{Y}(1)|C)p_C -  (\bar{Y}(0)|C)p_C )  +   ( (\bar{Y}(1)|A)p_A - (\bar{Y}(1)|A)p_A ) + \\
       & ( (\bar{Y}(1)|N)p_N  - (\bar{Y}(0)|N)p_N ) \\
       = & \left( (\bar{Y}(1)|C) -  (\bar{Y}(0)|C) \right)p_C   +  \\
       & \left( (\bar{Y}(1)|A)- (\bar{Y}(0)|A) \right)p_A  +  \left( (\bar{Y}(1)|N) - (\bar{Y}(0)|N) \right)p_N
\end{align}

## Learning about the ITT III

\begin{align}
ITT     = &   \bar{Y}(1) - \bar{Y}(0) \\
        = &  ( (\bar{Y}(1)|C)p_C + (\bar{Y}(1)|A)p_A + (\bar{Y}(1)|N)p_N ) - \\
       & ( (\bar{Y}(0)|C)p_C + (\bar{Y}(0)|A)p_A + (\bar{Y}(0)|N)p_N )  \\
        = &   ( (\bar{Y}(1)|C)p_C -  (\bar{Y}(0)|C)p_C )  +   ( (\bar{Y}(1)|A)p_A - (\bar{Y}(1)|A)p_A ) + \\
       & ( (\bar{Y}(1)|N)p_N  - (\bar{Y}(0)|N)p_N ) \\
        = &   ( (\bar{Y}(1)|C) -  (\bar{Y}(0)|C))p_C   +   ( (\bar{Y}(1)|A)- (\bar{Y}(0)|A))p_A  + \\
       & ( (\bar{Y}(1)|N) - (\bar{Y}(0)|N) )p_N
\end{align}


## Learning about the ITT IV

And, if the effect of the dose can only occur for those who open the door, and you can only open the door when assigned to do so then:

\begin{equation}
( (\bar{Y}(1)|A)- (\bar{Y}(0)|A))p_A = 0  \text{ and } ( (\bar{Y}(1)|N) - (\bar{Y}(0)|N) )p_N = 0
\end{equation}

And

\begin{equation}
ITT =  ( (\bar{Y}(1)|C) -  (\bar{Y}(0)|C))p_C  = ( CACE ) p_C.
\end{equation}


## The complier average causal effect I

We would also like to learn about the causal effect of answering the door and
having the conversation, the theoretically interesting effect.

But this comparison is confounded by $x$: a simple $\bar{Y}|D=1 - \bar{Y}|D=0$
comparison tells us about differences in the outcome due to $x$ in addition to
the difference caused by $D$.

\begin{center}
\begin{tikzcd}[ampersand replacement=\&]
Z  \arrow[from=1-1,to=1-2] \arrow[from=1-1, to=1-4, bend left, "\text{0 (exclusion)}"] \& D  \arrow[from=1-2,to=1-4] \& \& y \\
(x_1 \ldots x_p) \arrow[from=2-1,to=1-1, "\text{-.006 (as if randomized)}"]  \arrow[from=2-1,to=1-2, ".06"] \arrow[from=2-1,to=1-4, ".48"]
\end{tikzcd}
\end{center}

But we just saw that, in this design, and with these assumptions (including a
SUTVA assumption) that
$ITT =  ( (\bar{Y}(1)|C) -  (\bar{Y}(0)|C))p_C  = (CACE) p_C$, so we can define $CACE=ITT/p_C$.


## How to calculate the ITT and CACE/LATE I

```{r simivdesign, echo=FALSE}
prob_comply <- .8
tau <- .5

the_pop <- declare_population(
  N = 100,
  X = sample(1:4, N, replace = TRUE),
  u = rnorm(N),
  type = sample(c("Always-Taker", "Never-Taker", "Complier", "Defier"), N,
    replace = TRUE,
    prob = c(.1, 1 - unique(prob_comply), unique(prob_comply), 0)
  )
)

##  The unobserved potential outcomes,  Y(Z=1) and Y(Z=0) relate to the observed outcome, Y, via treatment assignment and a const  ant additive effect of tau.
## D refers to getting a dose of feedback
d_po <- declare_potential_outcomes(
  D ~ case_when(
    Z == 0 & type %in% c("Never-Taker", "Complier") ~ 0,
    Z == 1 & type %in% c("Never-Taker", "Defier") ~ 0,
    Z == 0 & type %in% c("Always-Taker", "Defier") ~ 1,
    Z == 1 & type %in% c("Always-Taker", "Complier") ~ 1
  )
)

y_po <- declare_potential_outcomes(
  Y ~ tau * sd(u) * D + u,
  assignment_variables = c("D", "Z")
)

## Treatment  assignment for  any given city is a simple fixed  proportion. It should be complete  or  urn-drawing assignment, no  t  simple or  coin-flipping assignment.
## theassign <- declare_assignment(m=m)
the_assign <- declare_assignment(Z = complete_ra(N = N))

## declare_reveal is basically the same as declare_potential_outcomes. I  think they  have this  here  to deal with situations of   missing data or non-compliance.
# thereveal <- declare_reveal(Y, Z)
d_reveal <- declare_reveal(D, assignment_variable = "Z")
y_reveal <- declare_reveal(Y, assignment_variables = c("D", "Z"))

base_design <- the_pop + the_assign + d_po + y_po + d_reveal + y_reveal

dat0 <- draw_data(base_design)

estimand_cace <- declare_inquiry(
  CACE = mean((Y_D_1_Z_1 + Y_D_1_Z_0) / 2 -
    (Y_D_0_Z_1 + Y_D_0_Z_0) / 2),
  subset = type == "Complier"
)
estimand_ate <- declare_inquiry(ATE = mean((Y_D_1_Z_1 + Y_D_1_Z_0) / 2 -
  (Y_D_0_Z_1 + Y_D_0_Z_0) / 2))
```

Some example data (where we know all potential outcomes):

```{r showdat0}
tempdat <- dat0[1:5, -1]
names(tempdat)[5] <- "pZ"
names(tempdat) <- gsub("_", "", names(tempdat))
kableExtra::kable(tempdat, digits = 2)
```

## How to calculate the ITT and CACE/LATE II

The ITT and CACE (the parts)

```{r echo=TRUE}
itt_y <- difference_in_means(Y ~ Z, data = dat0)
itt_y
itt_d <- difference_in_means(D ~ Z, data = dat0)
itt_d
```

## How to calculate the ITT and CACE/LATE III

All together:^[works when $Z \rightarrow D$ is not weak see @imbens2005robust for a cautionary tale]

```{r echo=TRUE}
cace_est <- iv_robust(Y ~ D | Z, data = dat0)
cace_est
## Notice same as below:
coef(itt_y)[["Z"]] / coef(itt_d)[["Z"]]
```

## Summary of Instrumental Variable based approach to the CACE/LATE

 - Analyze as you randomized, even when you don't control the dose
 - If you randomize treatment **assignment**, you can estimate the average effect of the dose on those who comply under the five assumptions that we made above:
    - $Z$ is randomized (so, breaking relationships with all $x$)
    - SUTVA
    - $Z$ has an effect on $D$ ("non-zero proportion of compliers")
    - No defiers
    - $Z$ only affects $Y$ through $D$ ("exclusion restriction")
 - The danger of per-protocol analysis (Comparing outcomes based on $D$ returns you to the world of observational studies).

# Open Discussion

## Open Discussion

Your questions and thoughts

## References {.allowframebreaks}
